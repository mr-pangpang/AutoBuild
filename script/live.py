import requests
import json

def decrypt_and_save(target_url):
    """
    è§£å¯†å¹¶ä¿å­˜æ–‡æœ¬å†…å®¹ï¼ŒåŒæ—¶æ¸…ç†æ³¨é‡Šè¡Œå’Œç‰¹å®šå­—æ®µï¼Œå¹¶åœ¨æœ€åæ·»åŠ æŒ‡å®šå†…å®¹
    """
    decrypt_api = "http://www.xn--sss604efuw.com/jm/jiemi.php"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        print(f"æ­£åœ¨è§£å¯†: {target_url}")
        response = requests.get(decrypt_api, params={'url': target_url}, headers=headers, timeout=30)
        
        if response.status_code == 200:
            content = response.text.strip()
            print(f"åŸå§‹å†…å®¹é•¿åº¦: {len(content)}")
            
            # æ¸…ç†æ³¨é‡Šè¡Œ
            content = clean_comments(content)
            print(f"æ¸…ç†æ³¨é‡Šåé•¿åº¦: {len(content)}")
            
            # ç¬¬ä¸€æ­¥ï¼šåˆ é™¤ ads å’Œ lives å­—æ®µ
            content = remove_specific_fields(content, ['"ads"', '"lives"'])
            
            # ç¬¬äºŒæ­¥ï¼šåˆ é™¤ç©ºç™½è¡Œ
            content = remove_blank_lines(content)
            
            # ç¬¬ä¸‰æ­¥ï¼šè§£æJSONå¹¶é‡æ–°ç»„ç»‡ç»“æ„
            content = reorganize_json_structure(content)
            
            # ç¬¬å››æ­¥ï¼šåˆ é™¤ proxy å­—æ®µ
            content = remove_specific_fields(content, ['"proxy"'])
            
            # ç¬¬äº”æ­¥ï¼šåœ¨å†…å®¹æœ€åæ·»åŠ æŒ‡å®šå­—æ®µ
            content = add_custom_fields(content)
            
            print(f"æœ€ç»ˆå†…å®¹é•¿åº¦: {len(content)}")
            
            # ä¿å­˜æ¸…ç†åçš„å†…å®¹
            with open("live", "w", encoding="utf-8") as f:
                f.write(content)
            
            print(f"âœ… è§£å¯†æˆåŠŸï¼å·²ä¿å­˜åˆ° live")
            print(f"ğŸ” å†…å®¹é¢„è§ˆ: {content[:200]}...")
        else:
            print(f"âŒ è§£å¯†å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")

def clean_comments(content):
    """
    æ¸…ç†æ³¨é‡Šè¡Œï¼Œç§»é™¤ä»¥//å¼€å¤´çš„è¡Œ
    """
    lines = content.split('\n')
    cleaned_lines = []
    
    for line in lines:
        stripped_line = line.strip()
        # ä¿ç•™éç©ºä¸”ä¸ä»¥//å¼€å¤´çš„è¡Œ
        if stripped_line and not stripped_line.startswith('//'):
            cleaned_lines.append(line)
    
    return '\n'.join(cleaned_lines)

def remove_specific_fields(content, fields_to_remove):
    """
    åˆ é™¤ç‰¹å®šçš„JSONå­—æ®µ
    """
    for field in fields_to_remove:
        print(f"æ­£åœ¨åˆ é™¤å­—æ®µ: {field}")
        
        # æŸ¥æ‰¾å­—æ®µå¼€å§‹ä½ç½®
        start_pos = content.find(field)
        if start_pos == -1:
            print(f"æœªæ‰¾åˆ°å­—æ®µ: {field}")
            continue
            
        # æ‰¾åˆ°å­—æ®µåçš„å†’å·
        colon_pos = content.find(':', start_pos)
        if colon_pos == -1:
            continue
            
        # ä»å†’å·åå¼€å§‹ï¼Œæ‰¾åˆ°å­—æ®µå€¼çš„ç»“æŸä½ç½®
        pos = colon_pos + 1
        brace_count = 0
        bracket_count = 0
        in_string = False
        escape_next = False
        
        while pos < len(content):
            char = content[pos]
            
            if escape_next:
                escape_next = False
            elif char == '\\':
                escape_next = True
            elif char == '"' and not escape_next:
                in_string = not in_string
            elif not in_string:
                if char == '{':
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                elif char == '[':
                    bracket_count += 1
                elif char == ']':
                    bracket_count -= 1
                elif char == ',' and brace_count == 0 and bracket_count == 0:
                    break
                elif char == '}' and brace_count == 0 and bracket_count == 0:
                    break
                elif char == ']' and brace_count == 0 and bracket_count == 0:
                    break
            
            pos += 1
        
        # åˆ é™¤ä»å­—æ®µåå¼€å§‹åˆ°å€¼ç»“æŸçš„ä½ç½®
        if pos < len(content):
            content = content[:start_pos] + content[pos+1:]
        else:
            content = content[:start_pos]
        
        print(f"å·²åˆ é™¤å­—æ®µ: {field}")
    
    # æ¸…ç†å¯èƒ½çš„å¤šä½™é€—å·
    content = content.replace(',,', ',')
    content = content.replace(',}', '}')
    content = content.replace(',]', ']')
    
    return content

def remove_blank_lines(content):
    """
    åˆ é™¤ç©ºç™½è¡Œ
    """
    lines = content.split('\n')
    non_blank_lines = []
    
    for line in lines:
        # ä¿ç•™éç©ºè¡Œï¼ˆåŒ…æ‹¬åªæœ‰ç©ºæ ¼ä½†ä¸æ˜¯å®Œå…¨ç©ºçš„è¡Œï¼‰
        if line.strip():
            non_blank_lines.append(line)
    
    cleaned_content = '\n'.join(non_blank_lines)
    print(f"åˆ é™¤ç©ºç™½è¡Œ: {len(lines)} -> {len(non_blank_lines)} è¡Œ")
    
    return cleaned_content

def reorganize_json_structure(content):
    """
    é‡æ–°ç»„ç»‡JSONç»“æ„ï¼Œå°†æŒ‡å®šé¡¹ç›®ç§»åŠ¨åˆ°"æœ¬åœ°æ’­æ”¾"ä¹‹å
    """
    print("æ­£åœ¨é‡æ–°ç»„ç»‡JSONç»“æ„...")
    
    # é¦–å…ˆå°è¯•æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡
    try:
        # æ‰¾åˆ°JSONçš„å¼€å§‹å’Œç»“æŸ
        json_start = content.find('{')
        json_end = content.rfind('}')
        
        if json_start == -1 or json_end == -1:
            print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONç»“æ„")
            return content
            
        # æå–æ•´ä¸ªJSONå†…å®¹
        json_content = content[json_start:json_end+1]
        
        # è§£æJSON
        data = json.loads(json_content)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«siteså­—æ®µ
        if 'sites' not in data:
            print("JSONä¸­æœªæ‰¾åˆ°siteså­—æ®µ")
            return content
            
        sites = data['sites']
        
        # æ‰¾åˆ°è¦ç§»åŠ¨çš„ä¸‰ä¸ªé¡¹ç›®å’Œç›®æ ‡ä½ç½®
        items_to_move = []
        remaining_items = []
        target_position = -1
        
        for i, site in enumerate(sites):
            key = site.get('key', '')
            
            if key == 'æœ¬åœ°æ’­æ”¾':
                target_position = i
            
            if key in ['æˆ‘çš„å¤¸å…‹', 'ç“œå­çœ‹çƒ', '88çœ‹çƒ']:
                items_to_move.append(site)
            else:
                remaining_items.append(site)
        
        if target_position == -1 or not items_to_move:
            print(f"æœªæ‰¾åˆ°ç›®æ ‡ä½ç½®æˆ–è¦ç§»åŠ¨çš„é¡¹ç›®: ç›®æ ‡ä½ç½®={target_position}, è¦ç§»åŠ¨çš„é¡¹ç›®æ•°={len(items_to_move)}")
            return content
        
        # é‡æ–°æ„å»ºsitesæ•°ç»„
        new_sites = []
        
        for i, site in enumerate(remaining_items):
            new_sites.append(site)
            # åœ¨"æœ¬åœ°æ’­æ”¾"ä¹‹åæ’å…¥è¦ç§»åŠ¨çš„é¡¹ç›®
            if site.get('key') == 'æœ¬åœ°æ’­æ”¾':
                new_sites.extend(items_to_move)
        
        # æ›´æ–°æ•°æ®
        data['sites'] = new_sites
        
        # é‡æ–°ç”ŸæˆJSONå­—ç¬¦ä¸²
        new_json = json.dumps(data, ensure_ascii=False, indent=2)
        
        # æ›¿æ¢åŸå†…å®¹
        new_content = content[:json_start] + new_json + content[json_end+1:]
        
        print(f"âœ… å·²é‡æ–°ç»„ç»‡JSONç»“æ„ï¼Œç§»åŠ¨äº† {len(items_to_move)} ä¸ªé¡¹ç›®")
        return new_content
        
    except json.JSONDecodeError as e:
        print(f"JSONè§£æé”™è¯¯: {e}")
        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨å­—ç¬¦ä¸²å¤„ç†æ–¹æ³•
        return reorganize_with_string_ops(content)
    except Exception as e:
        print(f"é‡æ–°ç»„ç»‡JSONç»“æ„æ—¶å‡ºé”™: {e}")
        return content

def reorganize_with_string_ops(content):
    """
    ä½¿ç”¨å­—ç¬¦ä¸²æ“ä½œé‡æ–°ç»„ç»‡ç»“æ„ï¼ˆJSONè§£æå¤±è´¥æ—¶çš„å¤‡ç”¨æ–¹æ³•ï¼‰
    """
    print("ä½¿ç”¨å­—ç¬¦ä¸²æ“ä½œé‡æ–°ç»„ç»‡ç»“æ„...")
    
    # å®šä¹‰è¦ç§»åŠ¨çš„ä¸‰ä¸ªé¡¹ç›®çš„å®Œæ•´æ–‡æœ¬
    items_to_move = [
        '''{"key":"æˆ‘çš„å¤¸å…‹","name":"ğŸ—½æˆ‘çš„â”ƒå¤¸å…‹","type":3,"api":"csp_MyQuarkGuard","searchable":0,"quickSearch":0,"changeable":0,"filterable":0,"indexs":0,"style":{"type":"list"},
"timeout":30}''',
        '''{"key":"ç“œå­çœ‹çƒ","name":"âš½ç“œå­â”ƒçœ‹çƒ","type":3,"api":"csp_GzSportGuard","searchable":0,"quickSearch":0,"changeable":0,"style":{"type":"list"},
"timeout":10}''',
        '''{"key":"88çœ‹çƒ","name":"âš½88â”ƒçœ‹çƒ","type":3,"api":"csp_KanqiuGuard","searchable":0,"quickSearch":0,"changeable":0,"style":{"type":"list"},
"timeout":10}'''
    ]
    
    # å®Œæ•´çš„"æœ¬åœ°æ’­æ”¾"é¡¹ç›®
    local_play_item = '''{"key":"æœ¬åœ°æ’­æ”¾","name":"ğŸ¼æœ¬åœ°â”ƒæ’­æ”¾","type":3,"api":"csp_LocalGuard","searchable":0,"changeable":0,"indexs":0,"style":{"type":"list"},
"timeout":5}'''
    
    # ç¬¬ä¸€æ­¥ï¼šä»å†…å®¹ä¸­åˆ é™¤è¿™ä¸‰ä¸ªé¡¹ç›®
    for item in items_to_move:
        # æ¸…ç†itemå­—ç¬¦ä¸²ä»¥ä¾¿æœç´¢
        clean_item = item.replace('\n', '').replace(' ', '')
        clean_content = content.replace('\n', '').replace(' ', '')
        
        # æŸ¥æ‰¾å¹¶åˆ é™¤
        pos = clean_content.find(clean_item)
        if pos != -1:
            # æ‰¾åˆ°åŸå§‹ä½ç½®
            orig_pos = content.find(item[:50])  # ä½¿ç”¨å‰50ä¸ªå­—ç¬¦æŸ¥æ‰¾åŸå§‹ä½ç½®
            if orig_pos != -1:
                # æ‰¾åˆ°é¡¹ç›®çš„ç»“æŸä½ç½®
                end_pos = content.find('}', orig_pos)
                if end_pos != -1:
                    end_pos += 1
                    # æ£€æŸ¥æ˜¯å¦æœ‰é€—å·
                    if end_pos < len(content) and content[end_pos] == ',':
                        end_pos += 1
                    content = content[:orig_pos] + content[end_pos:]
    
    # ç¬¬äºŒæ­¥ï¼šæ‰¾åˆ°"æœ¬åœ°æ’­æ”¾"é¡¹ç›®å¹¶åœ¨è¿™ä¹‹åæ’å…¥
    # å…ˆæ‰¾åˆ°å®Œæ•´çš„æœ¬åœ°æ’­æ”¾é¡¹ç›®
    local_pos = content.find(local_play_item)
    if local_pos != -1:
        # æ‰¾åˆ°é¡¹ç›®çš„ç»“æŸä½ç½®
        end_pos = local_pos + len(local_play_item)
        # ç¡®ä¿æœ‰é€—å·
        if end_pos < len(content) and content[end_pos] != ',':
            content = content[:end_pos] + ',\n' + content[end_pos:]
            end_pos += 2
        
        # æ„å»ºè¦æ’å…¥çš„å†…å®¹
        insert_content = ',\n'.join(items_to_move)
        
        # æ’å…¥åˆ°æœ¬åœ°æ’­æ”¾ä¹‹å
        content = content[:end_pos] + ',\n' + insert_content + content[end_pos:]
    
    return content

def add_custom_fields(content):
    """
    åœ¨JSONå†…å®¹æœ€åæ·»åŠ è‡ªå®šä¹‰å­—æ®µ
    """
    # ç¡®ä¿å†…å®¹ä»¥ } ç»“å°¾
    if content.endswith('}'):
        content = content[:-1]
    
    # è¦æ·»åŠ çš„è‡ªå®šä¹‰å†…å®¹
    custom_content = '''
"proxy":[
	"raw.githubusercontent.com",
	"googlevideo.com",
	"cdn.v82u1l.com",
	"cdn.iz8qkg.com",
	"cdn.kin6c1.com",
	"c.biggggg.com",
	"c.olddddd.com",
	"haiwaikan.com",
	"www.histar.tv",
	"youtube.com",
	"uhibo.com",
	".*boku.*",
	".*nivod.*",
	".*ulivetv.*"
	],
"hosts": [
	"hlsztemgsplive.miguvideo.com=hlsztemgsplive.miguvideo.com.b.cdn.chinamobile.com",
	"push-rtmp-hs-spe-f5.douyincdn.com=source-fcdn-spe-push.s.bytefcdn.com",
	"cdn9.163189.xyz=gcore.jsdelivr.net",
	"cache.ott.fifalive.itv.cmvideo.cn=cache.ott.fifalive.itv.cmvideo.cn.e.cdn.chinamobile.com",
	"studentlive.migucloud.com=base-v4v6-miguvideo.e.cdn.chinamobile.com"
	],
"ads":["static-mozai.4gtv.tv"],
"lives":[
{"name":"TV","type":0,"url":"https://ghproxy.net/https://raw.githubusercontent.com/dpdisk/m3u/main/tv","playerType":2,"timeout":10,"ua":"okHttp/Mod-1.4.0.0"},
{"name":"å†°èŒ¶TV","type":0,"url":"https://fy.188766.xyz/?ip=&mima=mianfeidehaimaiqian&json=true","playerType":2,"timeout":10,"ua":"bingcha/1.1"}
	]
}'''
    
    # å¦‚æœåŸå†…å®¹æœ«å°¾æœ‰é€—å·ï¼Œå…ˆå»æ‰
    if content.rstrip().endswith(','):
        content = content.rstrip()[:-1]
    
    # æ·»åŠ é€—å·å’Œè‡ªå®šä¹‰å†…å®¹
    if not content.rstrip().endswith(','):
        content = content.rstrip() + ','
    
    content += custom_content
    print("âœ… å·²æ·»åŠ è‡ªå®šä¹‰å­—æ®µ")
    
    return content

# ä½¿ç”¨
if __name__ == "__main__":
    decrypt_and_save("http://ok321.top/tv")
